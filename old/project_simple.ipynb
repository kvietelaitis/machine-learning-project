{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    },
    "title": "HAR Project - Simple Train/Test Notebook"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Human Activity Recognition — Simple Notebook\n",
        "\n",
        "Authors: girdauskaite + partner\n",
        "\n",
        "A compact, easy-to-run notebook that assumes you already have separate train and test CSV files. It:\n",
        "- Loads train/test CSVs\n",
        "- Aligns features and drops constant columns\n",
        "- Fits a StandardScaler on train and applies to test\n",
        "- Trains and evaluates: RandomForest, XGBoost, CatBoost (if available), and k-NN\n",
        "- Saves final models (optional)\n",
        "\n",
        "Run cells in order. Edit file paths in the config cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Uncomment to install missing packages in a clean environment\n",
        "# !pip install xgboost catboost scikit-learn seaborn matplotlib joblib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
        "import xgboost as xgb\n",
        "try:\n",
        "    from catboost import CatBoostClassifier\n",
        "except Exception:\n",
        "    CatBoostClassifier = None\n",
        "\n",
        "import joblib\n",
        "print('imports ready')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CONFIG: update these paths if needed\n",
        "TRAIN_CSV = 'activity_train.csv'\n",
        "TEST_CSV  = 'activity_test.csv'\n",
        "MODELS_DIR = 'models'\n",
        "os.makedirs(MODELS_DIR, exist_ok=True)\n",
        "\n",
        "label_map = {\n",
        "    1:'WALKING', 2:'WALKING_UPSTAIRS', 3:'WALKING_DOWNSTAIRS',\n",
        "    4:'SITTING', 5:'STANDING', 6:'LAYING',\n",
        "    7:'STAND_TO_SIT', 8:'SIT_TO_STAND', 9:'SIT_TO_LIE',\n",
        "    10:'LIE_TO_SIT', 11:'STAND_TO_LIE', 12:'LIE_TO_STAND'\n",
        "}\n",
        "RANDOM_STATE = 42\n",
        "print('config OK')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load CSVs\n",
        "df_train = pd.read_csv(TRAIN_CSV)\n",
        "df_test  = pd.read_csv(TEST_CSV)\n",
        "print('train shape:', df_train.shape)\n",
        "print('test  shape:', df_test.shape)\n",
        "print('train has activity?', 'activity' in df_train.columns)\n",
        "print('test  has activity?', 'activity' in df_test.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Separate X / y and align feature columns\n",
        "if 'activity' not in df_train.columns:\n",
        "    raise ValueError('Train CSV must contain column `activity`')\n",
        "\n",
        "y_train = df_train['activity'].copy()\n",
        "X_train = df_train.drop(columns=['activity'])\n",
        "\n",
        "if 'activity' in df_test.columns:\n",
        "    y_test = df_test['activity'].copy()\n",
        "    X_test = df_test.drop(columns=['activity'])\n",
        "else:\n",
        "    y_test = None\n",
        "    X_test = df_test.copy()\n",
        "\n",
        "# Keep only columns present in both\n",
        "common_cols = [c for c in X_train.columns if c in X_test.columns]\n",
        "X_train = X_train[common_cols].copy()\n",
        "X_test  = X_test[common_cols].copy()\n",
        "print('aligned feature count:', X_train.shape[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Drop columns that are constant in train\n",
        "const_cols = [c for c in X_train.columns if X_train[c].nunique() <= 1]\n",
        "if const_cols:\n",
        "    print('dropping', len(const_cols), 'constant columns')\n",
        "    X_train.drop(columns=const_cols, inplace=True)\n",
        "    X_test.drop(columns=const_cols, inplace=True)\n",
        "print('features after drop:', X_train.shape[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fit scaler on train and transform both sets (useful for k-NN)\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train_scaled = pd.DataFrame(scaler.transform(X_train), columns=X_train.columns, index=X_train.index)\n",
        "X_test_scaled  = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns, index=X_test.index)\n",
        "\n",
        "joblib.dump(scaler, os.path.join(MODELS_DIR, 'scaler.joblib'))\n",
        "print('scaler fitted and saved')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate(model, X, y, name):\n",
        "    y_pred = model.predict(X)\n",
        "    print('---', name)\n",
        "    print('Accuracy:', accuracy_score(y, y_pred))\n",
        "    print('Macro F1:', f1_score(y, y_pred, average='macro'))\n",
        "    print(classification_report(y, y_pred, zero_division=0))\n",
        "    cm = confusion_matrix(y, y_pred)\n",
        "    plt.figure(figsize=(6,5))\n",
        "    sns.heatmap(cm, cmap='Blues', annot=False)\n",
        "    plt.title(f'Confusion matrix: {name}')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1) RandomForest (quick)\n",
        "rf = RandomForestClassifier(n_estimators=200, class_weight='balanced', random_state=RANDOM_STATE, n_jobs=-1)\n",
        "rf.fit(X_train, y_train)\n",
        "if y_test is not None:\n",
        "    evaluate(rf, X_test, y_test, 'RandomForest')\n",
        "joblib.dump(rf, os.path.join(MODELS_DIR, 'rf.joblib'))\n",
        "print('RF saved')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2) XGBoost (quick)\n",
        "n_classes = y_train.nunique()\n",
        "xgb_clf = xgb.XGBClassifier(objective='multi:softprob', num_class=n_classes, use_label_encoder=False,\n",
        "                            eval_metric='mlogloss', random_state=RANDOM_STATE, n_jobs=-1)\n",
        "xgb_clf.fit(X_train, y_train)\n",
        "if y_test is not None:\n",
        "    evaluate(xgb_clf, X_test, y_test, 'XGBoost')\n",
        "xgb_clf.save_model(os.path.join(MODELS_DIR, 'xgb.json'))\n",
        "print('XGB saved')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3) CatBoost (if available)\n",
        "if CatBoostClassifier is None:\n",
        "    print('CatBoost not installed — skip')\n",
        "else:\n",
        "    cb = CatBoostClassifier(iterations=300, learning_rate=0.1, random_seed=RANDOM_STATE, verbose=0)\n",
        "    cb.fit(X_train, y_train)\n",
        "    if y_test is not None:\n",
        "        evaluate(cb, X_test, y_test, 'CatBoost')\n",
        "    cb.save_model(os.path.join(MODELS_DIR, 'catboost.cbm'))\n",
        "    print('CatBoost saved')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4) k-NN (using scaled data)\n",
        "knn = KNeighborsClassifier(n_neighbors=5, weights='distance')\n",
        "knn.fit(X_train_scaled, y_train)\n",
        "if y_test is not None:\n",
        "    evaluate(knn, X_test_scaled, y_test, 'k-NN (scaled)')\n",
        "joblib.dump(knn, os.path.join(MODELS_DIR, 'knn.joblib'))\n",
        "print('k-NN saved')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Notes\n",
        "- All preprocessing (dropping constant columns, scaler) was fit on the training set only and then applied to the test set.\n",
        "- Use cross-validation on the training set (StratifiedKFold) for any hyperparameter tuning — do not use the test set for tuning.\n",
        "- If you prefer not to save models, remove the joblib.save / save_model lines.\n",
        "- If the test CSV has no labels, set `y_test` to None (the notebook already handles that) and save predictions instead of evaluating.\n",
        "\n",
        "If you'd like, I can now:\n",
        "- add a small cross-validation tuning cell for each method (light-weight), or\n",
        "- add code to produce and save predictions when test labels are not present.\n",
        "Which would you like next?"
      ]
    }
  ]
}